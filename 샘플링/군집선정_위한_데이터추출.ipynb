{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minanalysis/review-liar_nlp_pjt/blob/main/%EC%83%98%ED%94%8C%EB%A7%81_%EA%B5%B0%EC%A7%91%EC%84%A0%EC%A0%95_%EC%9C%84%ED%95%9C_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%B6%94%EC%B6%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예시 : 샘플링 군집 추출을 위한 요인 2개 (장르,기간) 중 장르의 공포/스릴러"
      ],
      "metadata": {
        "id": "Pr4vHHLyAc9f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbRPkGTrseX_"
      },
      "source": [
        "## 데이터 프레임 자체 기본 전처리 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdEck9LXmAMb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import io\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJiTHgsUmDjY"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "myfile = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNGFHIsnrn9p"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72McNhtQm5xt"
      },
      "outputs": [],
      "source": [
        "df_horror= pd.read_csv(io.BytesIO(myfile['df_horror.csv']))\n",
        "df_horror"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wrOZNckTrYS"
      },
      "outputs": [],
      "source": [
        "df_horror['댓글']=df_horror['댓글'].str.replace('[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]','') #한글이 아닌 문자들은 모두 제거 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cTM9UdLTzJU"
      },
      "outputs": [],
      "source": [
        "df_horror['댓글']=df_horror['댓글'].replace('', np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPqvu2Swvemk"
      },
      "outputs": [],
      "source": [
        "df_horror=df_horror.dropna() # 결측행 제거 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhSbBXa3wgUr"
      },
      "outputs": [],
      "source": [
        "df_horror=df_horror.sample(50000)\n",
        "df_horror# 랜덤으로 샘플 5만개 추출 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n_hEbu_zzhx"
      },
      "outputs": [],
      "source": [
        "df_horror=df_horror.reset_index() # 인덱스 번호 재부여 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF8XXz1Xs1XT"
      },
      "source": [
        "## 텐서플로우 및 필요한 라이브러리, 형태소 분석기 패키지들 불러오기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUjlf8AnoBIZ"
      },
      "outputs": [],
      "source": [
        "! pip install konlpy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BNXU-1_pAhg"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import * \n",
        "\n",
        "okt = Okt()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSyyW-LIsjBf"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWsvqbT_sucB"
      },
      "outputs": [],
      "source": [
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZ5kvHx5uOLL"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MGXKSbLyVGZ"
      },
      "source": [
        "## 댓글 전처리 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A8ARVintUT0"
      },
      "source": [
        "### 띄어쓰기 교정 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NjY19eKwcOj"
      },
      "outputs": [],
      "source": [
        "from pykospacing import Spacing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubIzJaEix6px"
      },
      "outputs": [],
      "source": [
        "spacing=Spacing()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrixqYIGtyOy"
      },
      "outputs": [],
      "source": [
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WjzOQuJlx95Z"
      },
      "outputs": [],
      "source": [
        "horror_review_list = [] # 5만개의 리뷰( 리뷰 당 한 문서로 간주 ) 를 띄어쓰기 교정해서 리스트에 담기 \n",
        "                       # 추후에, 이 리스트 값으로 댓글 컬럼을 바꿔줄거임. 후, 토큰화 하여 새컬럼에 담아줄 것 \n",
        "for i in trange(len(df_horror['댓글'])):\n",
        "  horror_review_list.append(spacing(df_horror['댓글'][i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_j8L-nLyIZGV"
      },
      "outputs": [],
      "source": [
        "df_horror['댓글']=horror_review_list # 데이터프레임의 댓글컬럼을 띄어쓰기 교정한 문장으로 변경시켜줌 \n",
        "df_horror.to_csv('df_horror_save1.csv',index=False) #혹시몰라 중간저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf1Js0iouUKa"
      },
      "source": [
        "### 단어 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ea6ngTAzK_u0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BgrDuFCTJDKf"
      },
      "outputs": [],
      "source": [
        "word_tokens=[] \n",
        "for sentence in df_horror['댓글']:\n",
        "    word_tokens.append(okt.morphs(sentence)) # 형태소 분석기 이용 토큰화\n",
        "\n",
        "# word_tokens 라는 리스트의 형식 자체가, 한 문장 당 토큰화된 단어들이 리스트로 들어가고 , \n",
        "#그 '리스트'가 word_tokens라는 리스트의 값이 되는 것. 즉, 리스트를 값으로 가지는 리스트! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mqTHcUXu7JyZ"
      },
      "outputs": [],
      "source": [
        "len(word_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XdV82NiZM-j1"
      },
      "outputs": [],
      "source": [
        "tokenizer=Tokenizer() # 텐서플로우의 케라스 패키지의 토크나이저 불러온 것"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k5UPRo3oNG2h"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(word_tokens) # 토크나이저가 알아서 정수 인코딩을 해줌 ( 빈도수 높은게 낮은 인덱싱 ) \n",
        "# 지금 우리 단계에서는 정수 인코딩은 필요 없지만, 빈도수를 내주기 위해서 실행해줘야 함 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e7ULEdyDNjLd"
      },
      "outputs": [],
      "source": [
        "horror_freq=sorted(tokenizer.word_counts.items(), key= lambda x:x[1], reverse=True) \n",
        "# tokenizer.word_counts 는 각 단어당 빈도수를 보여줌. 딕셔너리 형식이라 빈도수가 높은대로 정렬하기 위해 람다 사용 \n",
        "# 우리는 워드클라우드 사용한다면, 사실상 필요없는 단계지만 육안으로 확인해봄 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k3I3QtKx6nh"
      },
      "source": [
        "## 워드클라우드 위한 작업 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H22S-rFNyG2v"
      },
      "source": [
        "### 토큰화 단어들 합치기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yhKF6cglQxk"
      },
      "outputs": [],
      "source": [
        "sum_words= sum(word_tokens,[])\n",
        "# 문장 당 토큰화된 단어들이 각각의 리스트로 들어간 것을 한 리스트로 모두 합쳐버리기 \n",
        "# 워드클라우드가 넣기 위해 이건 중복단어 같은 게 전혀 처리 안된, 단순히 한 리뷰 당 토큰화된 단어들의 집합임! 단어들이 빈도가 여러개인게 당연! "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_words"
      ],
      "metadata": {
        "id": "Ss_Jbpzgaw2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f44CLiOz3Xv4"
      },
      "outputs": [],
      "source": [
        "total_words = [] # 최종 단어집합 \n",
        "\n",
        "for i in sum_words:\n",
        "  if len(i) > 1:\n",
        "    total_words.append(i)\n",
        "  else:\n",
        "    continue\n",
        "\n",
        "# 단어 길이가 1 이하인 것은 정제\n",
        "# 길이와 불용어에 대한건 내일 얘기하면서 정의 해보기로 했음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o5h1BJjRPoQN"
      },
      "outputs": [],
      "source": [
        "total_words_df=pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VCFoWqLCPpYo"
      },
      "outputs": [],
      "source": [
        "total_words_df['total_words']=total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tOPqnhotPsyu"
      },
      "outputs": [],
      "source": [
        "total_words_df.to_csv('total_words_df2.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 불용어 제거 "
      ],
      "metadata": {
        "id": "291E2sUi0TXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_word = ['지', '임', '게', '하', '고', '을', '인', '듯', '의', '가', '이', '영화','은', '들', '는', '좀', '잘', '걍', '과', '와', '도', '를', '으로', '나','자', '에', '와', '네', '한', '하다', '았', '앗', '엇', '주', '되', '다', '따', '영','이', '걸', '만','즐','엔', '임', '후','왠','만','할','로','펌','무','적','원','치', '류','옆','타','함','구','호','수','못','랑','요','씨','보고','대','됨','번','테','력','박','습','라','데','옴','오','기','줌','않','함','그','거']"
      ],
      "metadata": {
        "id": "VMr5qTrb0VQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words2 = [] # 최종 단어집합 \n",
        "\n",
        "for i in sum_words:\n",
        "    if i not in stop_word:\n",
        "        total_words2.append(i)\n",
        "    else:\n",
        "        continue"
      ],
      "metadata": {
        "id": "_g7yv4L00W04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_words_df2=pd.DataFrame()"
      ],
      "metadata": {
        "id": "R35yiCj50cg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_words_df2['토큰단어']=total_words2"
      ],
      "metadata": {
        "id": "UqZHcsjz0ioQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_words_df2.to_csv('final_words_df2.csv',index=False)"
      ],
      "metadata": {
        "id": "L8ZxGIUd0mfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnspB9Vuy84r"
      },
      "source": [
        "### 토큰화된 단어들 컬럼으로 넣기 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XgGuvofylS5"
      },
      "outputs": [],
      "source": [
        "#불용어 처리 안한 단어들 , 우리가 사용할 건 위의 불용어 제거 csv\n",
        "\n",
        "df_horror['토큰단어']=word_tokens\n",
        "\n",
        "# 이건 for 문 돌려서 컬럼에 들어가는 값들을 리스트(['단어1','단어2','단어3'])가 아니라,\n",
        "# 그냥 ('단어1','단어2','단어3') 넣으려고 했는데 \n",
        "# 나중에 활용을 생각했을 때도 리스트로 넣어두는 것이 낫지 않을까 싶어서 그냥 넣었습니다!\n",
        "# 따라서, 컬럼이 기본 크롤링 함수로 인한 컬럼 + 영화제목 + 토큰단어 인 데이터프레임이나 위의 \n",
        "# total_words 리스트 중 하나를 내일 들고오심 될 것 같습니다 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMmFSHY_-PJC"
      },
      "outputs": [],
      "source": [
        "df_horror.to_csv('df_horror_save2.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TMmLwf_pAFep"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "샘플링 군집선정 위한 데이터추출",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "10eq6rp-YRp4s0wW-lQorAS9FvleSnrc-",
      "authorship_tag": "ABX9TyNLBCyk1eBEwjDx8wHhf47m",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
